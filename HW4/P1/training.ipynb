{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oxiZ42B4SwQ-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tests import test_prediction, test_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x5znxQhLSwRC"
   },
   "outputs": [],
   "source": [
    "# load all that we need\n",
    "\n",
    "dataset = np.load('../dataset/wiki.train.npy', allow_pickle=True)\n",
    "devset = np.load('../dataset/wiki.valid.npy', allow_pickle=True)\n",
    "fixtures_pred = np.load('../fixtures/prediction.npz')  # dev\n",
    "fixtures_gen = np.load('../fixtures/generation.npy')  # dev\n",
    "fixtures_pred_test = np.load('../fixtures/prediction_test.npz')  # test\n",
    "fixtures_gen_test = np.load('../fixtures/generation_test.npy')  # test\n",
    "vocab = np.load('../dataset/vocab.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OZNrJ8XvSwRF"
   },
   "outputs": [],
   "source": [
    "# data loader\n",
    "\n",
    "class LanguageModelDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.seq_len = 50 #window size\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        # concatenate your articles and build into batches\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.dataset)\n",
    "        dataset= np.concatenate(self.dataset)\n",
    "        seq_remainder = len(dataset) % self.seq_len\n",
    "        if seq_remainder == 0:\n",
    "            seq_remainder += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        X_list = dataset[:-seq_remainder].reshape(-1, self.seq_len)\n",
    "        \n",
    "        \n",
    "        Y_list = dataset[1:-seq_remainder + 1].reshape(-1, self.seq_len)\n",
    "        for i in range(len(X_list)//self.batch_size):\n",
    "            yield (torch.LongTensor(X_list[i*self.batch_size:(i+1)* self.batch_size]), torch.LongTensor(Y_list[i*self.batch_size:(i+1)* self.batch_size])) \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Zt-7YsTYSwRI"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, 512)\n",
    "        self.rnn = nn.LSTM(input_size = 512,hidden_size=1024,num_layers=3, batch_first=True)\n",
    "        self.prob_out = nn.Linear(1024, vocab_size)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x, hiddens=None):\n",
    "        embed = self.embed(x)\n",
    "        if hiddens is not None:\n",
    "            out, hidden = self.rnn(embed, hiddens)\n",
    "        else:\n",
    "            out, hidden = self.rnn(embed)\n",
    "        out = self.prob_out(out)\n",
    "        return out, hidden\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kIvZOIfjSwRK"
   },
   "outputs": [],
   "source": [
    "# model trainer\n",
    "\n",
    "class LanguageModelTrainer:\n",
    "    def __init__(self, model, loader, max_epochs=1, run_id='exp'):\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.predictions = []\n",
    "        self.predictions_test = []\n",
    "        self.generated_logits = []\n",
    "        self.generated = []\n",
    "        self.generated_logits_test = []\n",
    "        self.generated_test = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), 1e-3, weight_decay=1e-6)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train() # set to training mode\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        for batch_num, (inputs, targets) in enumerate(self.loader):\n",
    "            epoch_loss += self.train_batch(inputs, targets)\n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        inputs, targets = inputs.to('cuda'), targets.to('cuda')\n",
    "        outputs = self.model(inputs)[0]\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        loss = self.criterion(outputs.permute(0,2,1), targets)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def test(self):\n",
    "        # don't change these\n",
    "        self.model.eval() # set to eval mode\n",
    "        predictions = TestLanguageModel.prediction(fixtures_pred['inp'], self.model) # get predictions\n",
    "        self.predictions.append(predictions)\n",
    "        generated_logits = TestLanguageModel.generation(fixtures_gen, 10, self.model) # generated predictions for 10 words\n",
    "        generated_logits_test = TestLanguageModel.generation(fixtures_gen_test, 10, self.model)\n",
    "        nll = test_prediction(predictions, fixtures_pred['out'])\n",
    "        generated = test_generation(fixtures_gen, generated_logits, vocab)\n",
    "        generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n",
    "        self.val_losses.append(nll)\n",
    "        \n",
    "        self.generated.append(generated)\n",
    "        self.generated_test.append(generated_test)\n",
    "        self.generated_logits.append(generated_logits)\n",
    "        self.generated_logits_test.append(generated_logits_test)\n",
    "        \n",
    "        # generate predictions for test data\n",
    "        predictions_test = TestLanguageModel.prediction(fixtures_pred_test['inp'], self.model) # get predictions\n",
    "        self.predictions_test.append(predictions_test)\n",
    "            \n",
    "        print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, nll))\n",
    "        return nll\n",
    "\n",
    "    def save(self):\n",
    "        model_path = os.path.join('experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.model.state_dict()},\n",
    "            model_path)\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)), self.predictions[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)), self.predictions_test[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)), self.generated_logits[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)), self.generated_logits_test[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated_test[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xPI7_kZRSwRN"
   },
   "outputs": [],
   "source": [
    "class TestLanguageModel:\n",
    "    def prediction(inp, model):\n",
    "        \"\"\"\n",
    "            \n",
    "            :param inp:\n",
    "            :return: a np.ndarray of logits\n",
    "        \"\"\"\n",
    "        inp = torch.LongTensor(inp).to('cuda')\n",
    "        output = model(inp)[0]\n",
    "        prediction = output[:, -1].detach().cpu().numpy()\n",
    "        return prediction\n",
    "\n",
    "        \n",
    "    def generation(inp, forward, model):\n",
    "        \"\"\"\n",
    "\n",
    "            Generate a sequence of words given a starting sequence.\n",
    "            :param inp: Initial sequence of words (batch size, length)\n",
    "            :param forward: number of additional words to generate\n",
    "            :return: generated words (batch size, forward)\n",
    "        \"\"\"        \n",
    "        model.eval()\n",
    "        generated_words = []\n",
    "        with torch.no_grad():\n",
    "            inp = torch.LongTensor(inp).to('cuda')\n",
    "            output, hidden = model(inp)\n",
    "\n",
    "            output = output[:,-1, :]\n",
    "            curr_word = torch.argmax(output, dim=1)\n",
    "            curr_word = curr_word.unsqueeze(1)\n",
    "            generated_words.append(curr_word)\n",
    "            if (forward > 1):\n",
    "\n",
    "                    for i in range(forward - 1):\n",
    "                        output, hidden = model(curr_word, hidden)\n",
    "                        output = output[:, -1, :]\n",
    "                        curr_word = torch.argmax(output, dim=1)\n",
    "                        curr_word = curr_word.unsqueeze(1)\n",
    "                        generated_words.append(curr_word)\n",
    "\n",
    "            \n",
    "            generated_words = torch.cat(generated_words, dim=1)\n",
    "        return generated_words.detach().cpu().numpy()\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TiUrjbEjSwRQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "NUM_EPOCHS = 12\n",
    "BATCH_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2HCVG5YISwRW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./experiments/1610157072\n"
     ]
    }
   ],
   "source": [
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./experiments'):\n",
    "    os.mkdir('./experiments')\n",
    "os.mkdir('./experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DbHH6zXTSwRa"
   },
   "outputs": [],
   "source": [
    "model = LanguageModel(len(vocab))\n",
    "model.to('cuda')\n",
    "loader = LanguageModelDataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "trainer = LanguageModelTrainer(model=model, loader=loader, max_epochs=NUM_EPOCHS, run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7D8wTJkBSwRc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [1/12]   Loss: 7.4509\n",
      "[VAL]  Epoch [1/12]   Loss: 6.2043\n",
      "Saving model, predictions and generated output for epoch 0 with NLL: 6.2043266\n",
      "[TRAIN]  Epoch [2/12]   Loss: 6.3008\n",
      "[VAL]  Epoch [2/12]   Loss: 5.2565\n",
      "Saving model, predictions and generated output for epoch 1 with NLL: 5.2564735\n",
      "[TRAIN]  Epoch [3/12]   Loss: 5.7506\n",
      "[VAL]  Epoch [3/12]   Loss: 4.9647\n",
      "Saving model, predictions and generated output for epoch 2 with NLL: 4.9647474\n"
     ]
    }
   ],
   "source": [
    "best_nll = 1e30 \n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    trainer.train()\n",
    "    nll = trainer.test()\n",
    "    if nll < best_nll:\n",
    "        best_nll = nll\n",
    "        print(\"Saving model, predictions and generated output for epoch \"+str(epoch)+\" with NLL: \"+ str(best_nll))\n",
    "        trainer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2FmDqBCSwRf"
   },
   "outputs": [],
   "source": [
    "# Don't change these\n",
    "# plot training curves\n",
    "plt.figure()\n",
    "plt.plot(range(1, trainer.epochs + 1), trainer.train_losses, label='Training losses')\n",
    "plt.plot(range(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('NLL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipdbmqaGSwRh"
   },
   "outputs": [],
   "source": [
    "# see generated output\n",
    "print (trainer.generated[-1]) # get last generated output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
